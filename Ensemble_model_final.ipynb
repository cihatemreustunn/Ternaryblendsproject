{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a0554-0a71-4184-9f3f-ef2411012230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4068ad4-d3ec-400c-9444-d3a315511890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true-y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce8e72-c468-41ba-8f3c-595a21947bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data and create a DataFrame\n",
    "\n",
    "data1 = pd.read_csv(\"training_dataset.csv\") \n",
    "features = data1.iloc[:, [0, 1, 2, 3, 4, 5]]\n",
    "output = data1.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd579028-bb7d-4cc4-9c48-b774f299b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature vectors\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f32fa-9ed3-442e-82d3-7e8b63f60e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation, test partition\n",
    "\n",
    "X = scaled_features\n",
    "y = output\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101c2de-c7ba-4bd5-980f-9e1e236ffb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN model construction\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(45, activation='relu', input_shape=[6]))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4,decay=1e-4), \n",
    "              loss='mae', \n",
    "              metrics=[coeff_determination])\n",
    "    \n",
    "ann_model = model.fit(X_train, y_train, batch_size=128, epochs=2500, validation_data=(X_val, y_val))\n",
    "y_pred_ann = ann_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4eec-04c0-46d7-8577-afa416096f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing the model accuracy\n",
    "\n",
    "regression_results(y_test, y_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78053cae-2bb0-4c94-a7c0-9943db252404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new predictions\n",
    "\n",
    "test_data = pd.read_csv(\"Prediction_matrix.csv\") \n",
    "scaled_test_data = scaler.fit_transform(test_data)\n",
    "scaled_test_data = pd.DataFrame(scaled_test_data)\n",
    "\n",
    "ternary = []\n",
    "ternary.append(model.predict(scaled_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7798ac-4e48-47d3-9705-e056df7cfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the predictions into a CSV file\n",
    "\n",
    "print(ternary)\n",
    "import csv\n",
    "\n",
    "with open('Predictions.csv', 'w') as f:\n",
    "     \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "     \n",
    "    write.writerows(ternary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7559ba-cd90-4c81-bdb5-c16edfbe5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost predictions\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=150, booster='gbtree', learning_rate=0.2, random_state=0)\n",
    "\n",
    "# Train XGBoost\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgboost = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b4275-4648-4342-8471-73b3afda69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing the model accuracy\n",
    "\n",
    "regression_results(y_test, y_pred_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe312dcf-852a-4c43-9300-214a5d09e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different kernels to test\n",
    "\n",
    "rbfkernel = 1.0 * RBF(length_scale=0.1, length_scale_bounds=(1e-1, 10.0))\n",
    "expkernel = 1.0 * ExpSineSquared(\n",
    "    length_scale=1.0,\n",
    "    periodicity=3.0,\n",
    "    length_scale_bounds=(0.1, 10.0),\n",
    "    periodicity_bounds=(1.0, 10.0),\n",
    ")\n",
    "\n",
    "quadkernel = 1.0 * RationalQuadratic(length_scale=0.1, alpha=0.5, alpha_bounds=(1e-5, 1e15))\n",
    "maternkernel = 1.0 * Matern(length_scale=0.1, length_scale_bounds=(1e-1, 10.0), nu=1.5)\n",
    "\n",
    "# Train GPR\n",
    "\n",
    "gpr_model = GaussianProcessRegressor(kernel = quadkernel,random_state=0).fit(X_train, y_train)\n",
    "y_pred_gpr = gpr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957db22-b1af-4503-af77-ef1b2f6fd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing the model accuracy\n",
    "\n",
    "regression_results(y_test, y_pred_gpr)\n",
    "\n",
    "# New predictions can be made similar to ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c5edd-9459-4783-860b-da0e2a20fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final ensemble averaged model predictions\n",
    "\n",
    "# Make predictions using each model\n",
    "preds1 = ann_model.predict(scaled_test_data)\n",
    "preds2 = xgb_model.predict(scaled_test_data)\n",
    "preds3 = gpr_model.predict(scaled_test_data)\n",
    "\n",
    "# Average the predictions\n",
    "final_preds = (preds1 + preds2 + preds3) / 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
